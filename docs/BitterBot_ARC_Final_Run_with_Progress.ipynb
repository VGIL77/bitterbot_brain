{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udde0 BitterBot AI \u2014 ARC Prize 2025 Final Run\n",
        "This notebook trains and evaluates the BitterBot ARC model **entirely within the Kaggle environment**.\n",
        "- \u2705 No Internet\n",
        "- \u2705 No warm start\n",
        "- \u2705 GPU-only (no CPU fallback)\n",
        "- \u2705 Auto-writes submission.csv for final scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Environment Setup ---\n",
        "import os, random, json, torch, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def seed_all(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "seed_all(42)\n",
        "assert torch.cuda.is_available(), '\u274c CUDA device required for final run'\n",
        "device = torch.device('cuda')\n",
        "print(f'\u2705 Using GPU: {torch.cuda.get_device_name(0)} (Total GPUs: {torch.cuda.device_count()})')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Dataset Paths ---\n",
        "print('Available datasets in /kaggle/input:', os.listdir('/kaggle/input'))\n",
        "ARC_TRAIN_PATH = '/kaggle/input/arc-agi-2/ARC-AGI-2-main/data/training/'\n",
        "ARC_TEST_PATH  = '/kaggle/input/arc-agi-2/ARC-AGI-2-main/data/evaluation/'\n",
        "\n",
        "assert os.path.exists(ARC_TRAIN_PATH), 'Training data path not found!'\n",
        "assert os.path.exists(ARC_TEST_PATH), 'Eval data path not found!'\n",
        "print('Training samples:', len(os.listdir(ARC_TRAIN_PATH)))\n",
        "print('Evaluation samples:', len(os.listdir(ARC_TEST_PATH)))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Import BitterBot ---\n",
        "import sys\n",
        "sys.path.append('/kaggle/input/bitterbot-v01-v1')\n",
        "\n",
        "# Add progress bar and ETA tracking\nfrom tqdm.auto import tqdm\n\nprint('\ud83d\ude80 Starting training...')\nepochs = 150\nfor epoch in tqdm(range(epochs), desc='Training Epochs'):\n    train_model(model,\n                data_path=ARC_TRAIN_PATH,\n                epochs=1,\n                save_dir='/kaggle/working/checkpoints',\n                epoch_offset=epoch)\nprint('\u2705 All epochs complete.')\n",
        "from models.topas_arc_60M import TopasARC60M\n",
        "from trainers.train_parent import train_model\n",
        "from validation.eval_ttt import evaluate_tasks\n",
        "\n",
        "print('\u2705 BitterBot modules imported successfully.')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Train from Scratch (No Warm Start) ---\n",
        "model = TopasARC60M().to(device)\n",
        "model.train()\n",
        "\n",
        "# Add progress bar and ETA tracking\nfrom tqdm.auto import tqdm\n\nprint('\ud83d\ude80 Starting training...')\nepochs = 150\nfor epoch in tqdm(range(epochs), desc='Training Epochs'):\n    train_model(model,\n                data_path=ARC_TRAIN_PATH,\n                epochs=1,\n                save_dir='/kaggle/working/checkpoints',\n                epoch_offset=epoch)\nprint('\u2705 All epochs complete.')\n",
        "            data_path=ARC_TRAIN_PATH,\n",
        "            epochs=150,\n",
        "            save_dir='/kaggle/working/checkpoints')\n",
        "\n",
        "print('\ud83c\udfc1 Training complete and checkpoint saved.')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Evaluation and Submission ---\n",
        "model.eval()\n",
        "checkpoint = '/kaggle/working/checkpoints/final_epoch150.pt'\n",
        "torch.save(model.state_dict(), checkpoint)\n",
        "print('Checkpoint verified:', os.path.exists(checkpoint))\n",
        "\n",
        "evaluate_tasks(model,\n",
        "               data_path=ARC_TEST_PATH,\n",
        "               output_file='/kaggle/working/submission.csv')\n",
        "\n",
        "print('\u2705 Evaluation finished. Submission ready at /kaggle/working/submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Validate Submission ---\n",
        "import pandas as pd\n",
        "sub_path = '/kaggle/working/submission.csv'\n",
        "assert os.path.exists(sub_path), 'Submission file not created!'\n",
        "df = pd.read_csv(sub_path)\n",
        "print('Submission preview:')\n",
        "display(df.head())\n",
        "print(f'Total rows: {len(df)}, File size: {os.path.getsize(sub_path)/1024:.2f} KB')\n",
        "print('\ud83c\udfaf Notebook complete \u2014 Ready to commit for final scoring.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}