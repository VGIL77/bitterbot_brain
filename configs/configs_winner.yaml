# configs_winner.yaml — BitterBot's strong baseline for ARC-AGI-2
#
# Principles:
# - No uniform/democratic overrides in training
# - No DSL/beam during pretraining (PUCT at inference only)
# - Contrastive projection enabled (lambda=0.25)
# - Gradient-carrying dopamine replay with hard-pixel mining (λ ramps 0.05→0.8)
# - PUCT at inference with MDL penalty for simplicity bias
# - Cross-demo consistency for task-invariant features
# - Deterministic seeding for reproducibility
#
# Usage:
#   python train_parent.py --config configs_winner.yaml
#
# Override example:
#   python train_parent.py --config configs_winner.yaml --epochs 50 --lr 1e-4

training:
  seed: 1337
  batch_size: 16  # Adjust based on GPU memory (16 for 24GB, 8 for 16GB)
  epochs: 40
  optimizer: adamw
  lr: 3.0e-4
  weight_decay: 0.05
  max_grad_norm: 1.0  # Gradient clipping (0.5 in code, 1.0 for micro-steps)
  amp: true
  max_steps: 60000  # ~150 epochs * 400 steps

# Dataset selection (top-level, not nested under training)
dataset: arc2  # ARC-AGI-2 dataset

# PUCT search (inference only, not during pretraining)
puct:
  enabled: true
  sims: 1000  # Number of PUCT simulations (--puct-nodes)
  max_depth: 6  # Maximum program depth (--puct-depth)
  c_puct: 1.25  # Exploration constant (--c-puct)

# Pretraining settings (CRITICAL: no DSL search during training)
pretraining:
  use_dsl: false  # DO NOT run DSL/beam during pretrain (purity)
  label_smoothing: 0.05  # Already in code
  use_ebr: true  # Energy-Based Refinement at eval time

# Spike coding (neuromorphic routing and EBR guidance)
spike:
  # RelMem spike blending (gradient-safe concept selection)
  spike_alpha_max: 0.5  # Max spike influence on top-k routing (0.0 = disabled)
  lambda_spike_pretrain: 0.0  # Optional spike budget during training (0.0 = disabled, 0.01 = light)

  # EBR spike budget (HRM latent sparsity penalty)
  spike_k_ebr: 1  # Threshold parameter for EBR spikes (lower = more sparse)
  lambda_spike_ebr: 0.03  # Spike budget weight in EBR energy (0.0 = disabled)

# RelationalMemory (episodic world model)
relmem:
  strict: true  # Return empty bias instead of uniform fallback
  inverse_weight: 0.01  # RelMem inverse loss weight (--relmem-reg-alpha)
  op_bias_scale: 1.0  # Scale factor for op_bias retrieval
  max_concepts: 3072  # 48x baseline for dream themes + wormhole templates (spike routing keeps activation sparse)
  bind_iou: 0.25  # IoU threshold for concept binding (--relmem-bind-iou)

# Dopamine replay (hard-pixel mining with stagnation gating)
replay:
  enabled: true
  topk_pixels: 150  # Hard-pixel mining (top-K hardest pixels)
  lambda_start: 0.05  # Initial replay weight
  lambda_ramp_per_100_steps: 0.002  # Ramp rate
  lambda_max: 0.8  # Maximum replay weight
  micro_every: 30  # Replay-only microstep every N steps (--replay-micro-every)
  micro_k: 1  # Samples per microstep (--replay-micro-k)
  micro_lambda: 0.5  # LR multiplier for microsteps (--replay-micro-lambda)
  stagnation_patience: 200  # Steps without improvement to trigger gating (--stagnation-patience)
  buffer_size: 200  # Self-play buffer size (--selfplay-buffer-size)

# Contrastive projection (Dream/RelMem → encoder gradients)
contrastive:
  enabled: true
  margin: 0.3  # Margin for pos vs neg prototypes
  lambda: 0.25  # Loss weight (0.25 in code)

# Cross-demo consistency (task-invariant features)
demo_consistency:
  enabled: true
  lambda: 0.02  # Small weight (--use-demo-consistency)

# Dream-KL (op-prior supervision)
dream_kl:
  enabled: true
  lambda_min: 0.1  # Starting weight
  lambda_max: 1.0  # Max weight at 50 concepts
  eps_start: 0.01  # Epsilon floor (annealed to 0.001)
  eps_min: 0.001

# DreamEngine (exploration/routing, fenced in no_grad during training)
dream:
  enable_dream: true  # Enable DreamEngine (--enable-dream)
  micro_ticks: 1  # Micro-ticks per forward (--dream-micro-ticks)
  ripple_rate_hz: 0.8  # Ripple substrate update rate
  stdp_gain: 3.0  # Spike-timing-dependent plasticity gain
  wall_time_s: 2.0  # Max wall time for offline cycles (--dream-full-timeout / 300)

  # Dream pretrain (warm-start hierarchical abstractor and dream components)
  pretrain_epochs: 2  # 2 epochs for hierarchical warmup (default, overridden by phased_training.dream_pretrain_epochs if enabled)
  pretrain_batches: 200  # Batches per pretrain epoch
  pretrain_freeze_model: true  # Freeze main model during pretrain
  full_every: 4  # Full consolidation every 4 epochs

# ═══════════════════════════════════════════════════════════════════════════
# Phased Training (WGO Oracle Learning Pipeline)
# ═══════════════════════════════════════════════════════════════════════════
# Three-phase training for learned WGO (World Graph Oracle):
#   Phase 0: Dream pretrain (optional, 2 epochs)
#   Phase 1: Encoder warmup (simple forward, 2 epochs)
#   Phase 2: WGO supervised learning on synthetic tasks (3 epochs)
#   Phase 3: Joint training with learned WGO oracle (main training)
#
# Usage:
#   python train_parent.py --training-phases 1,2,3
#
# Expected improvement: +11-17% EM from learned WGO oracle

phased_training:
  # Enable phased training (set via --training-phases CLI arg)
  enabled: false  # Set to true via --training-phases 1,2,3
  training_phases: [1, 2, 3]  # Which phases to run (can override via CLI)

  # Phase 0: Dream pretrain (optional warm-start)
  dream_pretrain_epochs: 2  # Dream-only warmup before Phase 1
  dream_pretrain_batches: 200  # Batches per dream pretrain epoch

  # Phase 1: Encoder warmup (simple forward, CE loss only)
  phase1_epochs: 2  # Encoder foundation training

  # Phase 2: WGO supervised learning
  phase2_epochs: 2  # WGO head training on synthetic tasks
  phase2_synthetic_count: 12000  # Number of synthetic tasks to generate
  phase2_batch_size: 8  # Batch size for Phase 2 (can be different from main)
  phase2_val_split: 0.2  # Validation split for WGO training

  # Phase 3: Joint training (uses main training config)
  # phase3_epochs is set by training.epochs (main training loop)

# MDL penalty (simplicity bias in search, critical for ARC-AGI-2)
mdl:
  penalty: 0.02  # Program length penalty in beam/PUCT scoring (--mdl-penalty)

# Self-play / STaR
selfplay:
  enable: false  # Disabled by default (enable with --selfplay-enable)
  interval: 250  # Generate puzzles every N steps (--selfplay-interval)
  weight: 0.1  # Self-play loss weight (--selfplay-weight)
  topk: 3  # Puzzles per round (--selfplay-topk)

# Andromeda Cortex (predictive coding MoE layer for sparse abstractions)
cortex:
  enable_cortex: true  # Enable Andromeda Cortical Sheet
  columns: 8  # Expert columns (√8 ≈ 2.8 active per sample)
  column_dim: 256  # Hidden dimension per column
  depth: 2  # PC blocks per column (2-level hierarchy)
  gating_temp: 0.7  # Softmax temperature (lower = sparser)
  prior_scale_max: 1.5  # Max EBR prior scaling [0.67, 1.5]

  # Loss weights (conservative start to avoid aux spike)
  lambda_recon: 0.5  # Reconstruction loss weight
  lambda_entropy: 0.5  # Entropy flux regularization
  lambda_sparsity: 0.25  # KL sparsity penalty
  max_aux_ratio: 0.10  # Cap cortex at 10% of total loss

  # Cortex integration with search and refinement
  use_in_ebr: true  # Wire Cortex prior scales to EBR energy terms
  use_in_puct: false  # Wire Cortex op_bias to PUCT (disabled for conservative start)

# ═══════════════════════════════════════════════════════════════════════════
# SynergyFusion: Cortex + RelMem + BrainGraph Unified Priors
# ═══════════════════════════════════════════════════════════════════════════
# Fuses three sources of knowledge into gradient-carrying priors:
#   - Cortex: Predictive coding residuals (φ, κ, CGE scales)
#   - RelMem: Episodic concept embeddings + operation biases
#   - BrainGraph: Structural task embeddings (reversible knowledge graph)
#
# Outputs:
#   - op_prior_logits: DSL operation priors for search
#   - resid_nudge: Brain latent enrichment vector
#
# Architecture: Trust-gated blending with reparameterization trick for
# confidence-weighted gradients (precision-weighted prediction errors).
#
# Expected impact: +5-10pp EM from neurosymbolic prior fusion
# Param cost: +2-3M params (SynergyFusion module)

# SynergyFusion flat config (YAML loader flattens with underscores)
synergy_fusion_enabled: true  # ⚡ RE-ENABLED WITH DETACHED DOPAMINE FIXES ⚡
synergy_fusion_trust_temp: 1.0  # Temperature for stochastic trust weighting
synergy_fusion_lambda_kl: 1.0  # Confidence-weighted KL divergence weight
synergy_fusion_resid_weight: 0.2  # Brain residual nudge weight
synergy_fusion_op_prior_weight: 0.5  # Operation prior blending weight

# Logging and evaluation
logging:
  step_interval: 50  # Log every N steps
  eval_interval: 5  # Evaluate every N epochs (--eval-interval)
  metrics:
    - loss_ce
    - dopamine_replay
    - contrastive_projection
    - dream_op_kl
    - dream_feat_align
    - demo_consistency
    - relmem_inverse
    - exact_match
    - accuracy
    - mean_iou
    - cortex_pc_recon  # Cortex reconstruction loss
    - cortex_pc_entropy  # Cortex entropy flux
    - cortex_kl_sparsity  # Cortex sparsity loss

# Model architecture (optional overrides)
model:
  width: 512  # Encoder width (--model-width)
  slots: 64  # Number of object slots (--model-slots)

  # Hierarchical Abstraction (experimental - multi-level pattern extraction)
  use_hierarchical_abstraction: true  # Enable 4-level hierarchical pattern extraction

  # Inference-time monologue (multi-trajectory self-consistency)
  use_inference_monologue: true  # Enable monologue ensemble
  monologue_k: 8  # Number of diversified PUCT traces
  monologue_temp: 0.7  # Temperature for prior jittering (lower = less diverse)

  # Uni-hemispheric dreaming at inference (UHD-I)
  uhd_preticks: 12  # Dream micro-ticks before DSL search (0 = disabled)
  uhd_retrieval_w: 0.6  # Weight for dream op_bias in priors (0.0-1.0)

  # Critic head for EM likelihood prediction (HRM-aligned)
  use_critic_head: true  # Enable critic head (default: true)

# Curriculum (optional)
curriculum:
  enabled: false  # Start with all difficulties
  bucket_unlock_patience: 3  # EM streak to unlock next difficulty

# Refinement loop (Stage-6, inference only)
refine:
  iters: 5  # Max refinement iterations (updated)
  depth: 6  # PUCT depth per iteration (updated)
  simulations: 2000  # PUCT sims per iteration (updated)
  c_puct: 1.5  # PUCT exploration (updated)

# Alpha-ARC & Extended Settings
# (Monologue settings are in model: section above)
alpha_evolve: true
alpha_dsl_enable: true
alpha_dsl_sims: 400
alpha_dsl_max_depth: 10

beam: 24

hyla_max_depth: 4
hyla_beam_width: 50

enable_market: true
market_liquidity: 20.0

self_play_enable: true
self_play_games: 4

ttt_enable: true
ttt_steps: 2
ttt_lr: 0.001

use_ebr: true
ebr_iters: 5

# Nightmare (negative reinforcement, experimental)
nightmare:
  alpha: 0.08  # Negative reinforcement strength (--nightmare-alpha)
  min_interval: 200  # Min steps between cycles (--nightmare-min-interval)
  max_interval: 1000  # Max steps between cycles (--nightmare-max-interval)

# ═══════════════════════════════════════════════════════════════════════════
# Alpha-ARC Ω: Orbit-CEGIS (Symmetry-Quotiented Search + Certificate-Guided Induction)
# ═══════════════════════════════════════════════════════════════════════════
#
# Three novel components for ARC-AGI-2:
# 1. Orbit canonicalization: D₄ × color permutations (~8x search reduction)
# 2. Orbit-contrastive (OrthoNCE): enforces D₄-invariant features
# 3. CEGIS certificates: lightweight invariants from demos guide/prune PUCT
#
# References:
# - Group equivariance: Cohen & Welling 2016
# - CEGIS: Solar-Lezama et al. 2006 (Sketch synthesis)
# - Burnside's lemma: Polya enumeration theory

orbit_cegis:
  # Orbit canonicalization (D₄ dihedral group + color permutations)
  use_orbit_canon: true  # Enable canonicalization (--use-orbit-canon)
  orbit_loss_weight: 0.03  # OrthoNCE weight (--orbit-loss-weight, tune 0.02-0.08)

  # Certificate-guided inductive synthesis (CEGIS)
  certificates: soft  # Mode: off | soft (penalty) | hard (prune)
  # Mined invariants:
  #   - mass_conservation: non-zero pixel count preserved
  #   - palette_subset: output colors ⊆ input colors
  #   - shape_preservation: H×W constant
  #   - bbox_area: bounding box area monotonicity

  # Expected impact:
  # - Search space reduction: ~8x from D₄, ~2-3x from certificates
  # - Sample efficiency: fewer spurious color/rotation variants to learn
  # - EM improvement: sharper concept boundaries → higher exact match rate

# ═══════════════════════════════════════════════════════════════════════════
# HyLa Solver & Hypothesis Market (Certificate-Guided Neurosymbolic Search)
# ═══════════════════════════════════════════════════════════════════════════

# HyLa: Certificate-guided sketch synthesis
hyla:
  max_hyp: 32  # Max hypotheses per puzzle (--hyla-max-hyp)
  enable_warm_start: true  # Use HyLa priors for PUCT warm-start

# Hypothesis Market: LMSR-based hypothesis trading
market:
  liquidity: 25.0  # LMSR 'b' parameter (depth of market)
  op_bias_w: 0.60  # Weight for market priors in DSL search (0.0-1.0)
